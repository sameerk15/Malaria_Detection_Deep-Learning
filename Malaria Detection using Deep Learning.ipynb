{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding='same',activation='relu',input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range = 0.2, zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory('C:/Users/sameer/Downloads/Dataset/Dataset/Train',target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set=test_datagen.flow_from_directory('C:/Users/sameer/Downloads/Dataset/Dataset/Test',target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.6712 - accuracy: 0.6298 - val_loss: 0.6632 - val_accuracy: 0.6791\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 16s 1s/step - loss: 0.6139 - accuracy: 0.6538 - val_loss: 0.8160 - val_accuracy: 0.3657\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.5318 - accuracy: 0.7548 - val_loss: 0.8966 - val_accuracy: 0.5970\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 27s 2s/step - loss: 0.4681 - accuracy: 0.7620 - val_loss: 1.0971 - val_accuracy: 0.3209\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.4549 - accuracy: 0.7909 - val_loss: 0.8045 - val_accuracy: 0.5075\n"
     ]
    }
   ],
   "source": [
    "r=model.fit(training_set, validation_data=test_set,epochs=5,steps_per_epoch=len(training_set),validation_steps=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_set)  #since we have used two nodes therefore we get values and summation of them will be one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3948118 , 0.6051882 ],\n",
       "       [0.80713314, 0.19286688],\n",
       "       [0.4821968 , 0.51780325],\n",
       "       [0.45109886, 0.54890114],\n",
       "       [0.80895543, 0.19104455],\n",
       "       [0.63311464, 0.36688542],\n",
       "       [0.82059836, 0.17940159],\n",
       "       [0.84707147, 0.15292856],\n",
       "       [0.64581347, 0.35418653],\n",
       "       [0.84533685, 0.15466313],\n",
       "       [0.7574896 , 0.24251042],\n",
       "       [0.8711175 , 0.12888248],\n",
       "       [0.4704107 , 0.5295893 ],\n",
       "       [0.717091  , 0.28290898],\n",
       "       [0.53621566, 0.4637844 ],\n",
       "       [0.8614354 , 0.1385646 ],\n",
       "       [0.5894278 , 0.4105722 ],\n",
       "       [0.7312236 , 0.26877642],\n",
       "       [0.9628162 , 0.03718384],\n",
       "       [0.5244828 , 0.47551724],\n",
       "       [0.47352767, 0.52647233],\n",
       "       [0.83907276, 0.16092722],\n",
       "       [0.5700936 , 0.42990637],\n",
       "       [0.62522334, 0.37477663],\n",
       "       [0.8172881 , 0.18271196],\n",
       "       [0.55941445, 0.4405855 ],\n",
       "       [0.86686736, 0.13313256],\n",
       "       [0.45719764, 0.5428024 ],\n",
       "       [0.8108076 , 0.18919241],\n",
       "       [0.85615826, 0.14384168],\n",
       "       [0.90893376, 0.0910662 ],\n",
       "       [0.5585404 , 0.44145963],\n",
       "       [0.9223558 , 0.07764428],\n",
       "       [0.36031038, 0.6396896 ],\n",
       "       [0.7696956 , 0.23030445],\n",
       "       [0.62660927, 0.37339073],\n",
       "       [0.42969748, 0.5703025 ],\n",
       "       [0.3899172 , 0.6100828 ],\n",
       "       [0.89493483, 0.10506518],\n",
       "       [0.54774624, 0.4522538 ],\n",
       "       [0.6076917 , 0.3923083 ],\n",
       "       [0.53501505, 0.46498498],\n",
       "       [0.6891239 , 0.31087604],\n",
       "       [0.89866275, 0.10133726],\n",
       "       [0.5188928 , 0.48110723],\n",
       "       [0.812114  , 0.18788603],\n",
       "       [0.57498944, 0.42501053],\n",
       "       [0.4493389 , 0.5506611 ],\n",
       "       [0.67293763, 0.32706228],\n",
       "       [0.62772864, 0.3722713 ],\n",
       "       [0.5147247 , 0.48527533],\n",
       "       [0.43345398, 0.56654596],\n",
       "       [0.78986144, 0.21013853],\n",
       "       [0.7255352 , 0.27446476],\n",
       "       [0.8647024 , 0.1352976 ],\n",
       "       [0.84272766, 0.15727237],\n",
       "       [0.8787881 , 0.1212119 ],\n",
       "       [0.46895066, 0.5310494 ],\n",
       "       [0.5155811 , 0.4844189 ],\n",
       "       [0.49305674, 0.50694317],\n",
       "       [0.36298028, 0.6370197 ],\n",
       "       [0.58333814, 0.41666192],\n",
       "       [0.838999  , 0.16100101],\n",
       "       [0.5901849 , 0.409815  ],\n",
       "       [0.40915847, 0.59084153],\n",
       "       [0.789811  , 0.21018901],\n",
       "       [0.8412115 , 0.15878847],\n",
       "       [0.79668146, 0.20331852],\n",
       "       [0.8041658 , 0.19583425],\n",
       "       [0.47583887, 0.5241611 ],\n",
       "       [0.7379321 , 0.2620679 ],\n",
       "       [0.89600736, 0.10399271],\n",
       "       [0.63270265, 0.36729744],\n",
       "       [0.40376246, 0.5962375 ],\n",
       "       [0.79707676, 0.20292321],\n",
       "       [0.8132524 , 0.18674766],\n",
       "       [0.90593797, 0.09406206],\n",
       "       [0.43941653, 0.5605835 ],\n",
       "       [0.75948226, 0.24051775],\n",
       "       [0.6908601 , 0.30913988],\n",
       "       [0.7217994 , 0.27820066],\n",
       "       [0.6414303 , 0.35856962],\n",
       "       [0.7897173 , 0.21028267],\n",
       "       [0.59371763, 0.4062824 ],\n",
       "       [0.8008703 , 0.19912964],\n",
       "       [0.8181318 , 0.18186823],\n",
       "       [0.39186245, 0.60813755],\n",
       "       [0.85692865, 0.14307132],\n",
       "       [0.8617438 , 0.13825622],\n",
       "       [0.7095339 , 0.29046616],\n",
       "       [0.66633445, 0.33366552],\n",
       "       [0.8442924 , 0.15570761],\n",
       "       [0.8039863 , 0.19601376],\n",
       "       [0.7266269 , 0.27337313],\n",
       "       [0.84307355, 0.15692644],\n",
       "       [0.4785034 , 0.52149653],\n",
       "       [0.76670253, 0.23329748],\n",
       "       [0.49297047, 0.5070296 ],\n",
       "       [0.45008433, 0.5499157 ],\n",
       "       [0.9170275 , 0.08297248],\n",
       "       [0.8460613 , 0.15393871],\n",
       "       [0.5318484 , 0.4681516 ],\n",
       "       [0.63728154, 0.36271846],\n",
       "       [0.7116198 , 0.2883802 ],\n",
       "       [0.45114413, 0.54885584],\n",
       "       [0.77929527, 0.22070469],\n",
       "       [0.5764269 , 0.42357305],\n",
       "       [0.43941578, 0.5605842 ],\n",
       "       [0.56706005, 0.43294   ],\n",
       "       [0.66559106, 0.33440888],\n",
       "       [0.544438  , 0.455562  ],\n",
       "       [0.7512469 , 0.24875303],\n",
       "       [0.6746596 , 0.32534042],\n",
       "       [0.6525184 , 0.3474816 ],\n",
       "       [0.82713103, 0.17286897],\n",
       "       [0.70717406, 0.29282597],\n",
       "       [0.7044812 , 0.2955189 ],\n",
       "       [0.36740673, 0.6325933 ],\n",
       "       [0.8710344 , 0.12896566],\n",
       "       [0.7801704 , 0.21982965],\n",
       "       [0.75795346, 0.2420466 ],\n",
       "       [0.91972286, 0.08027713],\n",
       "       [0.88732547, 0.11267458],\n",
       "       [0.848419  , 0.15158097],\n",
       "       [0.3348341 , 0.6651659 ],\n",
       "       [0.65138656, 0.34861344],\n",
       "       [0.86300564, 0.13699435],\n",
       "       [0.6095063 , 0.3904937 ],\n",
       "       [0.8197357 , 0.1802643 ],\n",
       "       [0.86251676, 0.13748321],\n",
       "       [0.9244764 , 0.07552363],\n",
       "       [0.5446594 , 0.4553407 ],\n",
       "       [0.40518364, 0.5948163 ],\n",
       "       [0.72599995, 0.27400002]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred    #higher value on left side means it is parasitic and low values on right side means it is not parasitic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above, whcihever wil be the highest value, we will have to take that index (0 or 1) so we use argmax for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(y_pred,axis=1)  #argmax helps to get the index of the maximum number in tht row of array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred    #0 indicates the person is infected and 1 opposite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets read the image and predict whether it is infected or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('C:/Users/sameer/Downloads/Dataset/Dataset/Test/Uninfected/2.png',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 224, 224, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
